
===============================================================================

SemEval-2012 Task 2: Measuring Degrees of Relational Similarity

David A. Jurgens, Saif M. Mohammad, Peter D. Turney, and Keith J. Holyoak
February 10, 2012

This README-scripts.txt file describes the Perl scripts for scoring your algorithm for
SemEval-2012 Task 2. For information about SemEval-2012 Task 2, see the website
(https://sites.google.com/site/semeval2012task2/). This work is licensed under 
a Creative Commons Attribution-ShareAlike 3.0  Unported License
(http://creativecommons.org/licenses/by-sa/3.0/).

Summary

Degrees of relational similarity: the task is, given two pairs of words, 
A:B and C:D, determine the degree to which the semantic relations between 
A and B are similar to those between C and D. Unlike the more familiar task 
of semantic relation identification, which assigns each word pair to a 
discrete semantic relation class, this task recognizes the continuous range 
of degrees of relational similarity. In one sub-task, the challenge is to 
determine the degrees of relational similarity between given reference word
pairs and a variety of other pairs, mostly in the same general semantic 
relation class as the reference pair. In a second sub-task, the challenge is 
to first perform semantic relation identification (using, for example, the 
standard supervised learning approach to semantic relation classification) 
and then to estimate the degree to which each pair is a prototypical instance 
of its assigned semantic relation class. 

This scoring package focuses on the first sub-task, determining the degrees of 
relational similarity between given reference word pairs and a variety of 
other pairs. 

Quick Start

See the shell script "examples.sh" for a quick lesson on how to run the
Perl scripts.

Description of Perl Scripts

1. score_maxdiff.pl
   - this script takes a set of MaxDiff answers to be evaluated and
     compares them with Mechanical Turk answers to MaxDiff questions
   - a guess for a MaxDiff question is considered correct when
     the majority of Turkers agree with the guess (if two choices
     tie for majority, both are considered correct)
   - score_maxdiff.pl and score_scale.pl are the two ways that your
     algorithm will be evaluated

2. score_scale.pl
   - this script takes a set of ratings of word pairs, according to how
     prototypical they are for a given semantic relation, and scores
     the ratings by their Spearman correlation with a Gold Standard
   - we generate the Gold Standard ratings by running the Turkers'
     MaxDiff answers through the script maxdiff_to_scale.pl
   - score_maxdiff.pl and score_scale.pl are the two ways that your
     algorithm will be evaluated

3. maxdiff_to_scale.pl
   - this script converts MaxDiff answers to a list of word pairs, rated
     on a scale
   - the rating for a word pair is the percentage of times it is chosen
     by a Turker as Most Illustrative minus the percentage of times
     it is chosen as Least Illustrative
   - our Gold Standard ratings of the word pairs are generated by giving
     MaxDiff answers from the Amazon Mechanical Turk as input to this
     script
   - the Spearman correlation of your algorithm is based on comparison
     of the scale generated by your algorithm with our Gold Standard
     scale generated by this script

4. scale_to_maxdiff.pl
   - given a set of MaxDiff questions and a set of word pairs rated on a 
     scale, this script generates answers to the MaxDiff questions
   - in a MaxDiff question with four word pairs, the pair with the lowest
     rating is the guess for the Least Illustrative pair, and the pair
     with the highest rating is the guess for the Most Illustrative pair
   - most algorithms will generate a rating scale for the word pairs,
     and this script will be useful for converting these rated word
     pairs to answers to MaxDiff questions, so that the MaxDiff score
     of the algorithm can be calculated

5. random_scale.pl
   - this script assigns random scale ratings to a list of word pairs, as 
     a baseline for comparison
   - using scale_to_maxdiff.pl we can convert the random scale ratings
     to random MaxDiff answers, as another baseline for comparison

How to Use the Perl Scripts

See "examples.sh". The following describes what is happening in this
shell script. The output of "examples.sh" is in the subdirectory
"Examples".

1. random_scale.pl
   - the first step is to run your algorithm on the Phase 1 Answers of
     the Turkers
   - let's use random_scale.pl to play the role of your algorithm
   - random_scale.pl reads the Phase 1 word pairs and scores them
     randomly
   - your own algorithm would score the pairs by comparing them with
     the paradigm pairs (subcategories-paradigms.txt) or the
     definitions (subcategories-definitions.txt) or both
   - the score for a pair should represent the degree to which the
     given pair is a prototypical example of the given relation
   - edit random_scale.pl to read the desired pair file in Phase1Answers,
     such as "Phase1Answers/Phase1Answers-1a.txt", and write the ratings
     to a suitable file, such as "Examples/RandomScaled-1a.txt"
   - run random_scale.pl and take a look at the output file

2. maxdiff_to_scale.pl
   - the second step is to convert the Turkers' Phase 2 Answers to
     rating scores, so that the Turkers' answers can be compared
     with your algorithm's answers (or the random answers in 
     "Examples/RandomScaled-1a.txt")
   - edit maxdiff_to_scale.pl to read the Phase 2 Answers
     (e.g., "Phase2Answers/Phase2Answers-1a.txt") and write the ratings
     to a suitable file (e.g., "Examples/TurkerScaled-1a.txt")
   - run maxdiff_to_scale.pl and take a look at the output file

3. score_scale.pl
   - to calculate the Spearman correlation of the scores in your
     score file (e.g., "Examples/RandomScaled-1a.txt"), edit score_scale.pl
     to read your file ("Examples/RandomScaled-1a.txt") and the Turker
     file ("Examples/TurkerScaled-1a.txt") and write to a suitable output file
     (e.g., "Examples/SpearmanRandomScaled-1a.txt")
   - run score_scale.pl and take a look at the output file
   - random rating should have a Spearman correlation near zero

4. scale_to_maxdiff.pl
   - to calculate the MaxDiff score for your algorithm, you need to
     use your ratings (e.g., "Examples/RandomScaled-1a.txt") to answer
     the MaxDiff questions (e.g., "Phase2Questions/Phase2Questions-1a.txt")
   - edit scale_to_maxdiff.pl to read the question file
     ("Phase2Questions/Phase2Questions-1a.txt") and your rating file
     ("Examples/RandomScaled-1a.txt") and write to a suitable output file
     (e.g., "Examples/RandomMaxDiff-1a.txt")
   - run scale_to_maxdiff.pl and take a look at the output file

5. score_maxdiff.pl
   - to calculate the MaxDiff score for your algorithm, edit score_maxdiff.pl
     to read your MaxDiff answers ("Examples/RandomMaxDiff-1a.txt") and
     the Turkers' MaxDiff answers ("Phase2Answers/Phase2Answers-1a.txt") and 
     write to a suitable output file (e.g., "Examples/MaxDiffRandom-1a.txt")
   - run score_maxdiff.pl and take a look at the output file
   - random guessing should have an accuracy of about 25%, since there are
     four choices for each question

===============================================================================


